{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify fraud from Eron Email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context \n",
    "\n",
    "In 2000, Enron was one of the largest companies in the United States. By 2002, it had collapsed into bankruptcy due to widespread corporate fraud. In the resulting Federal investigation, a significant amount of typically confidential information entered into the public record, including tens of thousands of emails and detailed financial data for top executives. In this project, you will play detective, and put your new skills to use by building a person of interest identifier based on financial and email data made public as a result of the Enron scandal. To assist you in your detective work, we've combined this data with a hand-generated list of persons of interest in the fraud case, which means individuals who were indicted, reached a settlement or plea deal with the government, or testified in exchange for prosecution immunity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset\n",
    "\n",
    "As preprocessing to this project, we've combined the Enron email and financial data into a dictionary, where each key-value pair in the dictionary corresponds to one person. The dictionary key is the person's name, and the value is another dictionary, which contains the names of all the features and their values for that person. The features in the data fall into three major types, namely financial features, email features and POI labels.\n",
    "\n",
    "financial features: ['salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock', 'director_fees'] (all units are in US dollars)\n",
    "\n",
    "email features: ['to_messages', 'email_address', 'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi'] (units are generally number of emails messages; notable exception is ‘email_address’, which is a text string)\n",
    "\n",
    "POI label: [‘poi’] (boolean, represented as integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Dataset and Question\n",
    "\n",
    "- Data Exploration (related lesson: \"Datasets and Questions\"):\n",
    "\n",
    "Student response addresses the most important characteristics of the dataset and uses these characteristics to inform their analysis. Important characteristics include:\n",
    " total number of data points, \n",
    " allocation across classes (POI/non-POI), \n",
    " number of features used, \n",
    " are there features with many missing values?,etc\n",
    "\n",
    "- Outlier Investigation (related lesson: \"Outliers\"):\n",
    "Student response identifies outlier(s) in the financial data, and explains how they are removed or otherwise handled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "\n",
    "In this project I will use the libraries sys, pickle, pandas, numpy, matplot and pprint and the external file tester.\n",
    "\n",
    "I will use pickle to load the data; pandas and numpy to data manipulation, matplot to plot our visualizations and tester to test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreyai/anaconda/envs/bunnies/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle \n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "import tester\n",
    "\n",
    "%matplotlib inline\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dataset\n",
    "\n",
    "I will import the dataset that is in a final_project_dataset.pkl file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Dataset\n",
    "data_dict = pickle.load(open(\"../final_project/final_project_dataset.pkl\", \"r\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "In this part I will perform initial data analysis. \n",
    "First, we will see a instance of this data in order to get a sense of the data features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 600000,\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'mark.metts@enron.com',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 94299,\n",
       " 'from_messages': 29,\n",
       " 'from_poi_to_this_person': 38,\n",
       " 'from_this_person_to_poi': 1,\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 1740,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 585062,\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 365788,\n",
       " 'shared_receipt_with_poi': 702,\n",
       " 'to_messages': 807,\n",
       " 'total_payments': 1061827,\n",
       " 'total_stock_value': 585062}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.values()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 21 features some are financial features and others are email features. We can also see that we will need to handle with the NaN values. Let see the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21,\n",
       " ['salary',\n",
       "  'to_messages',\n",
       "  'deferral_payments',\n",
       "  'total_payments',\n",
       "  'exercised_stock_options',\n",
       "  'bonus',\n",
       "  'restricted_stock',\n",
       "  'shared_receipt_with_poi',\n",
       "  'restricted_stock_deferred',\n",
       "  'total_stock_value',\n",
       "  'expenses',\n",
       "  'loan_advances',\n",
       "  'from_messages',\n",
       "  'other',\n",
       "  'from_this_person_to_poi',\n",
       "  'poi',\n",
       "  'director_fees',\n",
       "  'deferred_income',\n",
       "  'long_term_incentive',\n",
       "  'email_address',\n",
       "  'from_poi_to_this_person'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict.values()[0].keys()),data_dict.values()[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets tranform to a pandas data_frame for a better data manipulation,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eron_data = pd.DataFrame.from_dict(data_dict, orient = 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how many people are poi in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of People Analyzed: ', 146)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "poi\n",
       "False    128\n",
       "True      18\n",
       "Name: salary, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of data points, allocation across classes (POI/non-POI) \n",
    "# number of features used, are there features with many missing values?\n",
    "\n",
    "# total number of data points, \n",
    "print(\"Number of People Analyzed: \",len(data_dict))\n",
    "# allocation across classes (POI/non-POI)\n",
    "\n",
    "eron_data.groupby('poi').count()['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x111a5d310>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEOCAYAAAB1g0unAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111a5d6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.despine(left=True)\n",
    "sns.countplot(x='poi',data=eron_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets treat our missing data. In order to do so we will need to first see how many NaN are on our dataset by each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PercentageMissin(Dataset):\n",
    "    \"\"\"this function will return the percentage of missing values in a dataset \"\"\"\n",
    "    if isinstance(Dataset,pd.DataFrame):\n",
    "        adict={} #a dictionary conatin keys columns names and values percentage of missin value in the columns\n",
    "        for feature in Dataset.columns:\n",
    "            count_nan_feature = 0;\n",
    "            for feature_row in Dataset[feature]:\n",
    "                if(feature_row == 'NaN'):\n",
    "                    count_nan_feature += 1  \n",
    "            adict[feature]=(count_nan_feature*100)/len(Dataset[feature])\n",
    "        return pd.DataFrame(adict,index=['% of missing'],columns=adict.keys())\n",
    "    else:\n",
    "        raise TypeError(\"can only be used with panda dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking of Missing Data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "loan_advances                97.0\n",
       "director_fees                88.0\n",
       "restricted_stock_deferred    87.0\n",
       "deferral_payments            73.0\n",
       "deferred_income              66.0\n",
       "long_term_incentive          54.0\n",
       "bonus                        43.0\n",
       "from_poi_to_this_person      41.0\n",
       "from_messages                41.0\n",
       "shared_receipt_with_poi      41.0\n",
       "from_this_person_to_poi      41.0\n",
       "to_messages                  41.0\n",
       "other                        36.0\n",
       "expenses                     34.0\n",
       "salary                       34.0\n",
       "exercised_stock_options      30.0\n",
       "restricted_stock             24.0\n",
       "email_address                23.0\n",
       "total_payments               14.0\n",
       "total_stock_value            13.0\n",
       "poi                           0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Ranking of Missing Data\")\n",
    "PercentageMissin(eron_data).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_fields =['poi','salary','bonus', 'long_term_incentive', 'deferred_income', 'deferral_payments',\n",
    "            'loan_advances', 'other','expenses', 'director_fees','total_payments']\n",
    "stock_fields =['poi','exercised_stock_options','restricted_stock','restricted_stock_deferred','total_stock_value']\n",
    "email_fields =['to_messages','from_messages','from_poi_to_this_person','from_this_person_to_poi','shared_receipt_with_poi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eron_data.loc[:,payment_fields] = eron_data.loc[:,payment_fields].replace('NaN', 0)\n",
    "eron_data.loc[:,stock_fields] = eron_data.loc[:,stock_fields].replace('NaN',0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eron_poi = eron_data[eron_data.poi == 1]\n",
    "eron_non_poi = eron_data[eron_data.poi == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreyai/anaconda/envs/bunnies/lib/python2.7/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy = 'mean', axis=0)\n",
    "\n",
    "eron_poi.loc[:, email_fields] = imp.fit_transform(eron_poi.loc[:,email_fields]);\n",
    "eron_non_poi.loc[:, email_fields] = imp.fit_transform(eron_non_poi.loc[:,email_fields]);\n",
    "\n",
    "eron_data = eron_poi.append(eron_non_poi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, BELDEN TIMOTHY N to YEAP SOON\n",
      "Data columns (total 21 columns):\n",
      "salary                       146 non-null int64\n",
      "to_messages                  146 non-null float64\n",
      "deferral_payments            146 non-null int64\n",
      "total_payments               146 non-null int64\n",
      "exercised_stock_options      146 non-null int64\n",
      "bonus                        146 non-null int64\n",
      "restricted_stock             146 non-null int64\n",
      "shared_receipt_with_poi      146 non-null float64\n",
      "restricted_stock_deferred    146 non-null int64\n",
      "total_stock_value            146 non-null int64\n",
      "expenses                     146 non-null int64\n",
      "loan_advances                146 non-null int64\n",
      "from_messages                146 non-null float64\n",
      "other                        146 non-null int64\n",
      "from_this_person_to_poi      146 non-null float64\n",
      "poi                          146 non-null bool\n",
      "director_fees                146 non-null int64\n",
      "deferred_income              146 non-null int64\n",
      "long_term_incentive          146 non-null int64\n",
      "email_address                146 non-null object\n",
      "from_poi_to_this_person      146 non-null float64\n",
      "dtypes: bool(1), float64(5), int64(14), object(1)\n",
      "memory usage: 24.1+ KB\n"
     ]
    }
   ],
   "source": [
    "eron_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no more missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BELDEN TIMOTHY N         True\n",
       "BOWEN JR RAYMOND M       True\n",
       "CALGER CHRISTOPHER F     True\n",
       "CAUSEY RICHARD A         True\n",
       "COLWELL WESLEY           True\n",
       "DELAINEY DAVID W         True\n",
       "FASTOW ANDREW S          True\n",
       "GLISAN JR BEN F          True\n",
       "HANNON KEVIN P           True\n",
       "HIRKO JOSEPH             True\n",
       "KOENIG MARK E            True\n",
       "KOPPER MICHAEL J         True\n",
       "LAY KENNETH L            True\n",
       "RICE KENNETH D           True\n",
       "RIEKER PAULA H           True\n",
       "SHELBY REX               True\n",
       "SKILLING JEFFREY K       True\n",
       "YEAGER F SCOTT           True\n",
       "ALLEN PHILLIP K         False\n",
       "BADUM JAMES P           False\n",
       "Name: poi, dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eron_data.head(20)['poi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "In this part we will find the outliers and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>other</th>\n",
       "      <th>expenses</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_payments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BELFER ROBERT</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-102500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3285</td>\n",
       "      <td>102500</td>\n",
       "      <td>102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHATNAGAR SANJAY</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>137864</td>\n",
       "      <td>0</td>\n",
       "      <td>137864</td>\n",
       "      <td>15456290</td>\n",
       "      <td>15456290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    poi  salary  bonus  long_term_incentive  deferred_income  \\\n",
       "BELFER ROBERT     False       0      0                    0                0   \n",
       "BHATNAGAR SANJAY  False       0      0                    0                0   \n",
       "\n",
       "                  deferral_payments  loan_advances   other  expenses  \\\n",
       "BELFER ROBERT               -102500              0       0         0   \n",
       "BHATNAGAR SANJAY                  0              0  137864         0   \n",
       "\n",
       "                  director_fees  total_payments  total_payments  \n",
       "BELFER ROBERT              3285          102500          102500  \n",
       "BHATNAGAR SANJAY         137864        15456290        15456290  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eron_data[eron_data[payment_fields[1:-1]].sum(axis='columns') != eron_data['total_payments']][payment_fields + ['total_payments']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BELFER ROBERT</th>\n",
       "      <td>False</td>\n",
       "      <td>3285</td>\n",
       "      <td>0</td>\n",
       "      <td>44093</td>\n",
       "      <td>-44093</td>\n",
       "      <td>-44093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHATNAGAR SANJAY</th>\n",
       "      <td>False</td>\n",
       "      <td>2604490</td>\n",
       "      <td>-2604490</td>\n",
       "      <td>15456290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    poi  exercised_stock_options  restricted_stock  \\\n",
       "BELFER ROBERT     False                     3285                 0   \n",
       "BHATNAGAR SANJAY  False                  2604490          -2604490   \n",
       "\n",
       "                  restricted_stock_deferred  total_stock_value  \\\n",
       "BELFER ROBERT                         44093             -44093   \n",
       "BHATNAGAR SANJAY                   15456290                  0   \n",
       "\n",
       "                  total_stock_value  \n",
       "BELFER ROBERT                -44093  \n",
       "BHATNAGAR SANJAY                  0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eron_data[eron_data[stock_fields[1:-1]].sum(axis='columns') != eron_data['total_stock_value']][stock_fields+['total_stock_value']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that only Belfer Robert and BHATNAGAR SANJAY had their data of total_payments and total_stock different from the payments_fields and stock_fields aggregate sum. Now looking at the eron pdf we can see that the values in the dataset were wrong. So we will now correct them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poi                            False\n",
       "salary                             0\n",
       "bonus                              0\n",
       "long_term_incentive                0\n",
       "deferred_income                    0\n",
       "deferral_payments            -102500\n",
       "loan_advances                      0\n",
       "other                              0\n",
       "expenses                        3285\n",
       "director_fees                 102500\n",
       "total_payments                  3285\n",
       "poi                            False\n",
       "exercised_stock_options            0\n",
       "restricted_stock               44093\n",
       "restricted_stock_deferred     -44093\n",
       "total_stock_value                  0\n",
       "Name: BELFER ROBERT, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Belfer Robert\n",
    "eron_data.loc['BELFER ROBERT','deffered_income'] = -102500\n",
    "eron_data.loc['BELFER ROBERT','defferral_payments'] = 0\n",
    "eron_data.loc['BELFER ROBERT','expenses'] = 3285\n",
    "eron_data.loc['BELFER ROBERT','director_fees'] = 102500\n",
    "eron_data.loc['BELFER ROBERT','total_payments'] = 3285\n",
    "\n",
    "eron_data.loc['BELFER ROBERT','exercised_stock_options'] = 0\n",
    "eron_data.loc['BELFER ROBERT','restricted_stock'] = 44093\n",
    "eron_data.loc['BELFER ROBERT','restricted_stock_deferred'] = -44093\n",
    "eron_data.loc['BELFER ROBERT','total_stock_value'] = 0\n",
    "\n",
    "eron_data.loc['BELFER ROBERT'][payment_fields+stock_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poi                             False\n",
       "salary                              0\n",
       "bonus                               0\n",
       "long_term_incentive                 0\n",
       "deferred_income                     0\n",
       "deferral_payments                   0\n",
       "loan_advances                       0\n",
       "other                               0\n",
       "expenses                       137864\n",
       "director_fees                       0\n",
       "total_payments                 137864\n",
       "poi                             False\n",
       "exercised_stock_options      15456290\n",
       "restricted_stock              2604490\n",
       "restricted_stock_deferred    -2604490\n",
       "total_stock_value            15456290\n",
       "Name: BHATNAGAR SANJAY, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Belfer Robert\n",
    "eron_data.loc['BHATNAGAR SANJAY','other'] = 0\n",
    "eron_data.loc['BHATNAGAR SANJAY','expenses'] = 137864\n",
    "eron_data.loc['BHATNAGAR SANJAY','director_fees'] = 0\n",
    "eron_data.loc['BHATNAGAR SANJAY','total_payments'] = 137864\n",
    "\n",
    "eron_data.loc['BHATNAGAR SANJAY','exercised_stock_options'] = 15456290\n",
    "eron_data.loc['BHATNAGAR SANJAY','restricted_stock'] = 2604490\n",
    "eron_data.loc['BHATNAGAR SANJAY','restricted_stock_deferred'] = -2604490\n",
    "eron_data.loc['BHATNAGAR SANJAY','total_stock_value'] = 15456290\n",
    "\n",
    "eron_data.loc['BHATNAGAR SANJAY'][payment_fields+stock_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>other</th>\n",
       "      <th>expenses</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>total_payments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [poi, salary, bonus, long_term_incentive, deferred_income, deferral_payments, loan_advances, other, expenses, director_fees, total_payments]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eron_data[eron_data[payment_fields[1:-1]].sum(axis='columns') != eron_data['total_payments']][payment_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [poi, exercised_stock_options, restricted_stock, restricted_stock_deferred, total_stock_value]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eron_data[eron_data[stock_fields[1:-1]].sum(axis='columns') != eron_data['total_stock_value']][stock_fields]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill all the incorrect data. Now lets see in the rows and their outliers and see if they are an oulier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "eron_data = eron_data.drop([\"TOTAL\",\"THE TRAVEL AGENCY IN THE PARK\"])\n",
    "\n",
    "# del data_dict[\"THE TRAVEL AGENCY IN THE PARK\"]\n",
    "# del data_dict[\"TOTAL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># of outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAY KENNETH L</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FREVERT MARK A</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHALLEY LAWRENCE G</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAVORATO JOHN J</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKILLING JEFFREY K</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KEAN STEVEN J</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DELAINEY DAVID W</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    # of outliers\n",
       "LAY KENNETH L                  14\n",
       "FREVERT MARK A                 12\n",
       "WHALLEY LAWRENCE G             11\n",
       "LAVORATO JOHN J                11\n",
       "SKILLING JEFFREY K              9\n",
       "KEAN STEVEN J                   8\n",
       "DELAINEY DAVID W                8"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Task 2: Remove outliers\n",
    "outliers = eron_data.quantile(.5) + 1.5 * (eron_data.quantile(.75)-eron_data.quantile(.25))\n",
    "outlier_pd = pd.DataFrame((eron_data[1:] > outliers[1:]).sum(axis = 1), columns = ['# of outliers']).\\\n",
    "    sort_values('# of outliers',  ascending = [0]).head(7)\n",
    "outlier_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># of outliers</th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>...</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>email_address</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>deffered_income</th>\n",
       "      <th>defferral_payments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAY KENNETH L</th>\n",
       "      <td>14</td>\n",
       "      <td>1072321</td>\n",
       "      <td>4273.0</td>\n",
       "      <td>202911</td>\n",
       "      <td>103559793</td>\n",
       "      <td>34348384</td>\n",
       "      <td>7000000</td>\n",
       "      <td>14761694</td>\n",
       "      <td>2411.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10359729</td>\n",
       "      <td>16.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>-300000</td>\n",
       "      <td>3600000</td>\n",
       "      <td>kenneth.lay@enron.com</td>\n",
       "      <td>123.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FREVERT MARK A</th>\n",
       "      <td>12</td>\n",
       "      <td>1060932</td>\n",
       "      <td>3275.0</td>\n",
       "      <td>6426990</td>\n",
       "      <td>17252530</td>\n",
       "      <td>10433518</td>\n",
       "      <td>2000000</td>\n",
       "      <td>4188667</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7427621</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-3367011</td>\n",
       "      <td>1617011</td>\n",
       "      <td>mark.frevert@enron.com</td>\n",
       "      <td>242.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHALLEY LAWRENCE G</th>\n",
       "      <td>11</td>\n",
       "      <td>510364</td>\n",
       "      <td>6019.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4677574</td>\n",
       "      <td>3282960</td>\n",
       "      <td>3000000</td>\n",
       "      <td>2796177</td>\n",
       "      <td>3920.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>301026</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>808346</td>\n",
       "      <td>greg.whalley@enron.com</td>\n",
       "      <td>186.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAVORATO JOHN J</th>\n",
       "      <td>11</td>\n",
       "      <td>339288</td>\n",
       "      <td>7259.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10425757</td>\n",
       "      <td>4158995</td>\n",
       "      <td>8000000</td>\n",
       "      <td>1008149</td>\n",
       "      <td>3962.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1552</td>\n",
       "      <td>411.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2035380</td>\n",
       "      <td>john.lavorato@enron.com</td>\n",
       "      <td>528.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKILLING JEFFREY K</th>\n",
       "      <td>9</td>\n",
       "      <td>1111258</td>\n",
       "      <td>3627.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8682716</td>\n",
       "      <td>19250000</td>\n",
       "      <td>5600000</td>\n",
       "      <td>6843672</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22122</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1920000</td>\n",
       "      <td>jeff.skilling@enron.com</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KEAN STEVEN J</th>\n",
       "      <td>8</td>\n",
       "      <td>404338</td>\n",
       "      <td>12754.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1747522</td>\n",
       "      <td>2022048</td>\n",
       "      <td>1000000</td>\n",
       "      <td>4131594</td>\n",
       "      <td>3639.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1231</td>\n",
       "      <td>387.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300000</td>\n",
       "      <td>steven.kean@enron.com</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DELAINEY DAVID W</th>\n",
       "      <td>8</td>\n",
       "      <td>365163</td>\n",
       "      <td>3093.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4747979</td>\n",
       "      <td>2291113</td>\n",
       "      <td>3000000</td>\n",
       "      <td>1323148</td>\n",
       "      <td>2097.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1661</td>\n",
       "      <td>609.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1294981</td>\n",
       "      <td>david.delainey@enron.com</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    # of outliers   salary  to_messages  deferral_payments  \\\n",
       "LAY KENNETH L                  14  1072321       4273.0             202911   \n",
       "FREVERT MARK A                 12  1060932       3275.0            6426990   \n",
       "WHALLEY LAWRENCE G             11   510364       6019.0                  0   \n",
       "LAVORATO JOHN J                11   339288       7259.0                  0   \n",
       "SKILLING JEFFREY K              9  1111258       3627.0                  0   \n",
       "KEAN STEVEN J                   8   404338      12754.0                  0   \n",
       "DELAINEY DAVID W                8   365163       3093.0                  0   \n",
       "\n",
       "                    total_payments  exercised_stock_options    bonus  \\\n",
       "LAY KENNETH L            103559793                 34348384  7000000   \n",
       "FREVERT MARK A            17252530                 10433518  2000000   \n",
       "WHALLEY LAWRENCE G         4677574                  3282960  3000000   \n",
       "LAVORATO JOHN J           10425757                  4158995  8000000   \n",
       "SKILLING JEFFREY K         8682716                 19250000  5600000   \n",
       "KEAN STEVEN J              1747522                  2022048  1000000   \n",
       "DELAINEY DAVID W           4747979                  2291113  3000000   \n",
       "\n",
       "                    restricted_stock  shared_receipt_with_poi  \\\n",
       "LAY KENNETH L               14761694                   2411.0   \n",
       "FREVERT MARK A               4188667                   2979.0   \n",
       "WHALLEY LAWRENCE G           2796177                   3920.0   \n",
       "LAVORATO JOHN J              1008149                   3962.0   \n",
       "SKILLING JEFFREY K           6843672                   2042.0   \n",
       "KEAN STEVEN J                4131594                   3639.0   \n",
       "DELAINEY DAVID W             1323148                   2097.0   \n",
       "\n",
       "                    restricted_stock_deferred         ...             other  \\\n",
       "LAY KENNETH L                               0         ...          10359729   \n",
       "FREVERT MARK A                              0         ...           7427621   \n",
       "WHALLEY LAWRENCE G                          0         ...            301026   \n",
       "LAVORATO JOHN J                             0         ...              1552   \n",
       "SKILLING JEFFREY K                          0         ...             22122   \n",
       "KEAN STEVEN J                               0         ...              1231   \n",
       "DELAINEY DAVID W                            0         ...              1661   \n",
       "\n",
       "                    from_this_person_to_poi    poi  director_fees  \\\n",
       "LAY KENNETH L                          16.0   True              0   \n",
       "FREVERT MARK A                          6.0  False              0   \n",
       "WHALLEY LAWRENCE G                     24.0  False              0   \n",
       "LAVORATO JOHN J                       411.0  False              0   \n",
       "SKILLING JEFFREY K                     30.0   True              0   \n",
       "KEAN STEVEN J                         387.0  False              0   \n",
       "DELAINEY DAVID W                      609.0   True              0   \n",
       "\n",
       "                    deferred_income  long_term_incentive  \\\n",
       "LAY KENNETH L               -300000              3600000   \n",
       "FREVERT MARK A             -3367011              1617011   \n",
       "WHALLEY LAWRENCE G                0               808346   \n",
       "LAVORATO JOHN J                   0              2035380   \n",
       "SKILLING JEFFREY K                0              1920000   \n",
       "KEAN STEVEN J                     0               300000   \n",
       "DELAINEY DAVID W                  0              1294981   \n",
       "\n",
       "                               email_address  from_poi_to_this_person  \\\n",
       "LAY KENNETH L          kenneth.lay@enron.com                    123.0   \n",
       "FREVERT MARK A        mark.frevert@enron.com                    242.0   \n",
       "WHALLEY LAWRENCE G    greg.whalley@enron.com                    186.0   \n",
       "LAVORATO JOHN J      john.lavorato@enron.com                    528.0   \n",
       "SKILLING JEFFREY K   jeff.skilling@enron.com                     88.0   \n",
       "KEAN STEVEN J          steven.kean@enron.com                    140.0   \n",
       "DELAINEY DAVID W    david.delainey@enron.com                     66.0   \n",
       "\n",
       "                    deffered_income  defferral_payments  \n",
       "LAY KENNETH L                   NaN                 NaN  \n",
       "FREVERT MARK A                  NaN                 NaN  \n",
       "WHALLEY LAWRENCE G              NaN                 NaN  \n",
       "LAVORATO JOHN J                 NaN                 NaN  \n",
       "SKILLING JEFFREY K              NaN                 NaN  \n",
       "KEAN STEVEN J                   NaN                 NaN  \n",
       "DELAINEY DAVID W                NaN                 NaN  \n",
       "\n",
       "[7 rows x 24 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd = outlier_pd.join(eron_data)\n",
    "pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use only 2 finacial data. First we will analyze the salary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salary outlier\n",
    "\n",
    "outliers = []\n",
    "for key in data_dict:\n",
    "    val = data_dict[key]['salary']\n",
    "    if val == 'NaN':\n",
    "        continue\n",
    "    outliers.append((key,int(val)))\n",
    "\n",
    "for point in data:\n",
    "    stock = point[2]\n",
    "    salary = point[1]\n",
    "    matplotlib.pyplot.scatter( salary, stock )\n",
    "\n",
    "matplotlib.pyplot.xlabel(\"salary\")\n",
    "matplotlib.pyplot.ylabel(\"restricted_stock\")\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have a big outlier in our data set. So lets see what it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(sorted(outliers,key=lambda x:x[1],reverse=True)[:3])\n",
    "\n",
    "for point in data:\n",
    "    stock = point[2]\n",
    "    salary = point[1]\n",
    "    if(salary < 26704229):\n",
    "\t    matplotlib.pyplot.scatter( salary, stock,color=\"b\" )\n",
    "\n",
    "matplotlib.pyplot.xlabel(\"salary\")\n",
    "matplotlib.pyplot.ylabel(\"stock options\")\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got that our outlier was the TOTAL.And others seem fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del data_dict[\"TOTAL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then lets investigate the restricted_stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate Outlier for restricted_stock\n",
    "outliers = []\n",
    "for key in data_dict:\n",
    "    val = data_dict[key]['restricted_stock']\n",
    "    if val == 'NaN':\n",
    "        continue\n",
    "    outliers.append((key,int(val)))\n",
    "    \n",
    "pprint(sorted(outliers,key=lambda x:x[1])[:3])\n",
    "pprint(sorted(outliers,key=lambda x:x[1],reverse=True)[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems that we do not have a outlier for restricted stock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing that strike my attention was the number of missing data in loan_advances,director_fees, restricted_stock_deferred, deferral_payments. Seems we have just a few of those and I if it wll be usefull to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_advances_df = eron_data[eron_data.loan_advances != 'NaN'][['loan_advances','poi']]\n",
    "print(\"There are \",len(loan_advances_df),\" points in our dataset.\")\n",
    "loan_advances_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we gae only four poins in our dataset and only one is a poi so I will not consider this from our feature list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_fees_df = eron_data[eron_data.director_fees != 'NaN'][['director_fees','poi']]\n",
    "print(\"There are \",len(director_fees_df),\" points in our dataset.\")\n",
    "director_fees_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 146 values we have only 17 entries and from those all 17 are false to poi parameter. So I will also not consider in my analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restricted_stock_deferred_df = eron_data[eron_data.restricted_stock_deferred != 'NaN'][['restricted_stock_deferred','poi']]\n",
    "print(\"There are \",len(restricted_stock_deferred_df),\" points in our dataset.\")\n",
    "restricted_stock_deferred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same happened with restricted_store_deferred as with the director_fee. From 146 values we have only 18 entries and from those all are false to poi parameter. So I will also not consider in my analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deferral_payments_df = eron_data[eron_data.deferral_payments != 'NaN'][['deferral_payments','poi']]\n",
    "print(\"There are \",len(deferral_payments_df),\" points in our dataset.\")\n",
    "deferral_payments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deferral_payments_df.groupby('poi').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found some poi in deferral payments!! There were 5 poi out of 39 people in this feature. Let see  if plotting the values we found some more information about this points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot('poi','deferral_payments',data=deferral_payments_df,fit_reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deferral_payments_df[\"deferral_payments\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deferral_payments_df[deferral_payments_df[\"deferral_payments\"] == 32083396]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that the highest value was he total and it should be an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot('poi','deferral_payments',data=deferral_payments_df[deferral_payments_df < 32083396],fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also noticed that ther are no much difference between the values of poi and non poi for the deferral payments. Most of the poi felt almost like in the middle of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The others features contain almost 50% of the data so I will use them in my analysis. Other thing is the email_address is unique amoung the people, so I will not use these variable.\n",
    "The features loan_advances, directors_fees, restricted_stock_deffered and email_address will be use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: \n",
    "Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question. Were there any outliers in the data when you got it, and how did you handle those?  [relevant rubric items: “data exploration”, “outlier investigation”]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to succesfully identify the POIs of the Eron scandal. In order to do it I will use machine learning classify algorithm, that can throught the data identify patterns of the POI. In this project I will use the dataset contaning some financial data and  email data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = [\n",
    "    'poi', 'to_messages','from_messages', 'from_poi_to_this_person','from_this_person_to_poi', \n",
    "    'salary','deferral_payments', 'other','total_payments','bonus', \n",
    "    'total_stock_value', 'shared_receipt_with_poi', 'long_term_incentive',\n",
    "    'exercised_stock_options','deferred_income', 'expenses', 'restricted_stock']\n",
    "\n",
    "# In the featureFormat it will treat the missing values giving them a 0  value\n",
    "data = featureFormat(data_dict, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize Feature Selection/Engineering:\n",
    "- Create new features (related lesson: \"Feature Selection\"): \n",
    "\n",
    "At least one new feature is implemented. Justification for that feature is provided in the written response. The effect of that feature on final algorithm performance is tested or its strength is compared to other features in feature selection. The student is not required to include their new feature in their final feature set.\n",
    "\n",
    "- Intelligently select features (related lesson: \"Feature Selection\"):\n",
    "\n",
    "Univariate or recursive feature selection is deployed, or features are selected by hand (different combinations of features are attempted, and the performance is documented for each one). Features that are selected are reported and the number of features selected is justified. For an algorithm that supports getting the feature importances (e.g. decision tree) or feature scores (e.g. SelectKBest), those are documented as well.\n",
    "\n",
    "- Properly scale features (related lesson: \"Feature Scaling\")\n",
    "\n",
    "If algorithm calls for scaled features, feature scaling is deployed.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Creating new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eron_data[eron_data['to_messages'] < eron_data['from_poi_to_this_person']][['from_poi_to_this_person', 'to_messages']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eron_data[eron_data['from_messages'] < eron_data['from_this_person_to_poi']][['from_this_person_to_poi', 'from_messages']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "# 'to_messages', 'from_messages', 'shared_receipt_with_poi', 'from_this_person_to_poi', 'from_poi_to_this_person'\n",
    "def compute_fraction_poi_total_messages(poi_messages, total_messages):\n",
    "    fraction_messages = 0.\n",
    "    \n",
    "    if(poi_messages !='NaN' and total_messages != 'NaN'):\n",
    "        fraction_messages = poi_messages/total_messages\n",
    "    \n",
    "    return fraction_messages\n",
    "\n",
    "def compute_fraction_from_poi_to_person(person_data):\n",
    "\n",
    "    qtd_messages_total = person_data['to_messages']\n",
    "    qtd_messages_from_poi = person_data['from_poi_to_this_person']\n",
    "    fraction_messages_from_poi = compute_fraction_poi_total_messages(qtd_messages_from_poi,qtd_messages_total)\n",
    "    \n",
    "    return fraction_messages_from_poi\n",
    "\n",
    "def compute_fraction_from_person_to_poi(person_data):\n",
    "    \n",
    "    qtd_messages_to_total = person_data['from_messages']\n",
    "    qtd_messages_to_poi = person_data['from_this_person_to_poi']\n",
    "    fraction_messages_to_poi = compute_fraction_poi_total_messages( qtd_messages_to_poi, qtd_messages_to_total)\n",
    "    \n",
    "    return fraction_messages_to_poi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineer a new feature\n",
    "\n",
    "\n",
    "for person_name in my_dataset:\n",
    "    person_data = my_dataset[person_name]\n",
    "    person_data[\"fraction_messages_from_poi\"] = compute_fraction_from_poi_to_person(person_data);\n",
    "    person_data[\"fraction_messages_to_poi\"] = compute_fraction_from_person_to_poi(person_data);\n",
    "    print(person_data[\"fraction_messages_from_poi\"],person_data[\"fraction_messages_to_poi\"])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_dataset['BANNANTINE JAMES M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_features = [\"fraction_messages_from_poi\",\"fraction_messages_to_poi\"]\n",
    "\n",
    "for feature_name in new_features:\n",
    "    if feature_name  not in features_list:\n",
    "        features_list.append(feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot new features\n",
    "fraction_list = ['poi','fraction_messages_from_poi','fraction_messages_to_poi']\n",
    "data_fraction = featureFormat(my_dataset,fraction_list)\n",
    "for point in data_fraction:\n",
    "    from_point = point[1]\n",
    "    to_point = point[2]\n",
    "    if point[0] == 1:\n",
    "        plt.scatter(from_point,to_point,color=\"r\",marker=\"*\")\n",
    "    else:\n",
    "        plt.scatter(from_point, to_point,color=\"b\")\n",
    "plt.ylabel(\"From this person to Poi\")\n",
    "plt.xlabel('From Poi to this person')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features_list = ['poi','salary', 'restricted_stock','bonus', \n",
    "#                  'total_payments', 'total_stock_value','expenses',\n",
    "#                  'fraction_messages_from_poi','fraction_messages_to_poi','from_this_person_to_poi', 'from_poi_to_this_person']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "print(\"Initial data shape:\", data.shape)\n",
    "print(\"Feature_list:\", features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(features)\n",
    "\n",
    "data.shape,features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "data_pd = pd.DataFrame(data=data)\n",
    "corr = data_pd.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection - selectionkbest, select percentile,lasso regression\n",
    "from sklearn.feature_selection import SelectPercentile,SelectKBest,chi2\n",
    "\n",
    "selector = SelectKBest(k=5)\n",
    "new_data = selector.fit_transform(features,labels)\n",
    "scores_KB = selector.scores_\n",
    "\n",
    "print(\"Final shape of parameters\",new_data.shape)\n",
    "print(\"Feature scores:\",selector.scores_)\n",
    "                                                                                                                                                                                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "scores = selector.scores_\n",
    "print(scores)\n",
    "indices = np.argsort(scores)[::-1]\n",
    "print(indices)\n",
    "print 'Feature Ranking'\n",
    "for i in range(len(scores)-1): \n",
    "    print \"{} feature {} ({})\".format(i+1,features_list[indices[i]+1],scores[indices[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used SelectBestK with k = 3. Then I stayed with the top 3 features: ['salary','restricted_stock','bonus']. I also noticed that they all are financial data. With them I got in a DecisionTree an accuracy of 0.83, a recall of 0.44 and a precision of 0.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "#Pca\n",
    "pca = PCA(n_components=3)\n",
    "features = pca.fit_transform(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature scalling for restricted stock\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# def standarlize_matrix(arr):\n",
    "#     standardScaler = StandardScaler()\n",
    "#     arr_standerized = standardScaler.fit_transform(arr)\n",
    "#     return arr;\n",
    "\n",
    "# data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "\n",
    "# new_data = standarlize_matrix(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# line = 0\n",
    "# for row in my_dataset:\n",
    "#     i = 0;\n",
    "#     for feature in features_list:\n",
    "#         if(line < len(new_data)):\n",
    "#             my_dataset[row][feature] = new_data[line][i]\n",
    "#         i += 1;\n",
    "#     line += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried two types of feature scalling: min-max (normalization) and also standalization. I notice that with min-max my accuracy went worse than without feature scalling. Then I tried standardlization and it performed better than without it improving our accuracy from 0.83 to near 0.86. In my opinion, it is due to the way that min-max treats outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: \n",
    "What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not? As part of the assignment, you should attempt to engineer your own feature that does not come ready-made in the dataset -- explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importances of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values.  [relevant rubric items: “create new features”, “intelligently select features”, “properly scale features”]\n",
    "\n",
    "\n",
    "#### Answer\n",
    "\n",
    "I end up using in my POI identifier the features 'poi', 'salary', 'restricted_stock', 'bonus', 'total_payments', 'total_stock_value' to select them I used the SelectKBest and I end up latter scalling them in oder to to standarlize the features. I created two new variables fraction of emails received from POI and fraction of emails sent to poi. I noticed that the features that helped me to identify poi were the financial features.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick an Algorithm\n",
    "\n",
    "- Pick an algorithm (related lessons: \"Naive Bayes\" through \"Choose Your Own Algorithm\")\n",
    "\n",
    "At least two different algorithms are attempted and their performance is compared, with the best performing one used in the final analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first separate between train and test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(my_data)\n",
    "\n",
    "# Train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function that will help to compute metrics.\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "\n",
    "def compute_metrics(predict,labels_test):\n",
    "\n",
    "    accuracy = accuracy_score(predict,labels_test);\n",
    "    recall = recall_score(predict,labels_test);\n",
    "    precision = precision_score(predict,labels_test);\n",
    "\n",
    "    print \"Accuracy Score: {}%\".format(accuracy) + \" Recall Score: {}%\".format(recall) + \" Precision Score: {}%\".format(precision);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will peak an algorithm.\n",
    "I will try to fit with:\n",
    "    - Knn\n",
    "    - Decision Tree\n",
    "    - Random Forest\n",
    "    - Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "# Provided to give you a starting point. Try a variety of classifiers.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train,labels_train)\n",
    "predict = clf.predict(features_test)\n",
    "compute_metrics(predict,labels_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(features_train,labels_train)\n",
    "predict = clf.predict(features_test)\n",
    "compute_metrics(predict,labels_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features_train,labels_train)\n",
    "\n",
    "predict = clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(predict,labels_test);\n",
    "print(predict,labels_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=110)\n",
    "clf.fit(features_train,labels_train)\n",
    "predict = clf.predict(features_test)\n",
    "compute_metrics(predict,labels_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(features_train,labels_train)\n",
    "predict = clf.predict(features_test)\n",
    "compute_metrics(predict,labels_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "What algorithm did you end up using? What other one(s) did you try? How did model performance differ between algorithms?  [relevant rubric item: “pick an algorithm”]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I tried to use knn, naive bayes, decision trees and some ensembles classifiers like adaboost and random forest. I noticed that with knn. I had a better accuracy so I picked as my final algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune an Algorithm\n",
    "\n",
    "- Discuss parameter tuning and its importance.:\n",
    "\n",
    "Response addresses what it means to perform parameter tuning and why it is important.\n",
    "\n",
    "- Tune the algorithm (related lesson: \"Validation\"):\n",
    "\n",
    "At least one important parameter tuned with at least 3 settings investigated systematically, or any of the following are true:\n",
    "\n",
    "GridSearchCV used for parameter tuning\n",
    "Several parameters tuned\n",
    "Parameter tuning incorporated into algorithm selection (i.e. parameters tuned for more than one algorithm, and best algorithm-tune combination selected for final analysis).\n",
    "\n",
    "\n",
    "- Algorithm Performance\n",
    "\n",
    "When tester.py is used to evaluate performance, precision and recall are both at least 0.3.\n",
    "\n",
    "- Validation Strategy (related lesson \"Validation\")\n",
    "\n",
    "Performance of the final algorithm selected is assessed by splitting the data into training and testing sets or through the use of cross validation, noting the specific type of validation performed. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV\n",
    "\n",
    "def init_cross_validation(train_reduced, labels):\n",
    "    \n",
    "    cross_validation = StratifiedKFold(n_splits=3)\n",
    "    cross_validation.get_n_splits(train_reduced, labels)\n",
    "    \n",
    "    return cross_validation;\n",
    "\n",
    "def generate_grid_search_model(model,parameters,train_reduced,labels):\n",
    "    \n",
    "    cross_validation = init_cross_validation(train_reduced, labels);\n",
    "    \n",
    "    grid_search = GridSearchCV(model,\n",
    "                               scoring='accuracy',\n",
    "                               param_grid = parameters,\n",
    "                               cv = cross_validation)\n",
    "\n",
    "    grid_search.fit(train_reduced, labels)\n",
    "    model = grid_search\n",
    "    parameters = grid_search.best_params_\n",
    "\n",
    "    print('Best score: {}'.format(grid_search.best_score_))\n",
    "    print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_KNeighbors(train_reduced,labels,run_grid_search=False):\n",
    "    \n",
    "    if run_grid_search:\n",
    "        \n",
    "        parameter_grid = {\n",
    "            'n_neighbors' : [3,4,5],\n",
    "            'weights' : ['distance','uniform'],\n",
    "            'leaf_size':[30,40],\n",
    "            'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "            'p': [1,2,3]\n",
    "        }\n",
    "        clf =  KNeighborsClassifier()\n",
    "        clf = generate_grid_search_model(clf,parameter_grid,train_reduced,labels)\n",
    "    else: \n",
    "        parameters = {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'auto', 'p': 2}\n",
    "        clf = KNeighborsClassifier(**parameters)\n",
    "        clf.fit(train_reduced, labels)\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_random_forest(train_reduced,labels,run_grid_search=False):\n",
    "    \n",
    "    if run_grid_search:\n",
    "        \n",
    "        parameter_grid = {\n",
    "            'max_depth' : [4, 6, 8],\n",
    "            'n_estimators': [50,100],\n",
    "            'max_features': ['sqrt', 'auto', 'log2'],\n",
    "            'min_samples_split': [3, 10],\n",
    "            'min_samples_leaf': [1, 3, 10],\n",
    "            'bootstrap': [True, False],\n",
    "        }\n",
    "        clf = RandomForestClassifier()\n",
    "        clf = generate_grid_search_model(clf,parameter_grid,train_reduced,labels)\n",
    "    else: \n",
    "        parameters = {\n",
    "            'bootstrap': False, 'min_samples_leaf': 1, \n",
    "            'n_estimators': 50, 'min_samples_split': 3, \n",
    "            'max_features': 'sqrt', 'max_depth': 4\n",
    "        }\n",
    "\n",
    "        clf = RandomForestClassifier(**parameters)\n",
    "        clf.fit(train_reduced, labels)\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_AdaBoost(train_reduced,labels,run_grid_search=False):\n",
    "    \n",
    "    if run_grid_search:\n",
    "        \n",
    "        parameter_grid = {\n",
    "            'n_estimators': [100,110,120,130,150,170]\n",
    "        }\n",
    "        clf = AdaBoostClassifier()\n",
    "        clf = generate_grid_search_model(clf,parameter_grid,train_reduced,labels)\n",
    "    else: \n",
    "        parameters = {\n",
    "            'n_estimators': 130\n",
    "        }\n",
    "\n",
    "        clf = AdaBoostClassifier(**parameters)\n",
    "        clf.fit(train_reduced, labels)\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clf =  create_KNeighbors(features,labels,run_grid_search=False)\n",
    "clf =  create_random_forest(features,labels,run_grid_search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = create_AdaBoost(features,labels,run_grid_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf = GaussianNB()\n",
    "# clf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question\n",
    "What does it mean to tune the parameters of an algorithm, and what can happen if you don’t do this well?  How did you tune the parameters of your particular algorithm? What parameters did you tune? (Some algorithms do not have parameters that you need to tune -- if this is the case for the one you picked, identify and briefly explain how you would have done it for the model that was not your final choice or a different model that does utilize parameter tuning, e.g. a decision tree classifier).  [relevant rubric items: “discuss parameter tuning”, “tune the algorithm”]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Tuning the algorithm means finding the best parameters for a certain model, that gives a better results. \n",
    "I tuned my particular algorithm with GridSearchCV. For my Adaboost model I tuned the n_estimators. And the final result was "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate and Evaluate\n",
    "- Usage of Evaluation Metrics (related lesson: \"Evaluation Metrics\")\n",
    "\t\n",
    "At least two appropriate metrics are used to evaluate algorithm performance (e.g. precision and recall), and the student articulates what those metrics measure in context of the project task.\n",
    "\n",
    "- Discuss validation and its importance.\n",
    "\n",
    "Response addresses what validation is and why it is important.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = clf.predict(features_test)\n",
    "compute_metrics(predict,labels_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "tester.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question\n",
    "What is validation, and what’s a classic mistake you can make if you do it wrong? How did you validate your analysis?  [relevant rubric items: “discuss validation”, “validation strategy”]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation process is when you divided your dataset into train, test datasets. A classic mistake is to not divide into these to dataset and use the entire data to train your model. I validade my model using a croess-validation (that means dividing my dataset into small chucks and using most of them to train and a chuck to test and then repeat the process).To validate my model I used a  k-fold = 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: \n",
    "\n",
    "Give at least 2 evaluation metrics and your average performance for each of them.  Explain an interpretation of your metrics that says something human-understandable about your algorithm’s performance. [relevant rubric item: “usage of evaluation metrics”]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also to validate I used the accuracy, reacall and prediction socer. In my final model I got Accuracy Score: 100% Recall Score: 100% Precision Score: 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
